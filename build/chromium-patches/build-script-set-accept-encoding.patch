From 5f4bbf82717d07b0fc6f8fa3c096fa4a74bfe4be Mon Sep 17 00:00:00 2001
From: Nico Weber <thakis@chromium.org>
Date: Mon, 10 Jan 2022 16:50:21 +0000
Subject: [PATCH] clang scripts: Make DownloadUrl() understand gzip encoding

Without `Accept-Encoding: gzip`, we don't actually get the smaller data.
Instead, it's just-in-time decompressed on the server now.
Now, we just download 1.6MB instead of 11MB and decompress on the client
instead. (I verified that after decompression, we produce the same bytes
as both `curl` and `curl --compressed`, which do server-side and
client-side decompression too, respectively.)

This has the added benefit that we now get a `Content-Length` header
in the response again, which happens to unbreak the ToT bots.

Bug: 1267363
Change-Id: If7b49952d164fc2df963edf50a9f00b882772563
Reviewed-on: https://chromium-review.googlesource.com/c/chromium/src/+/3377922
Reviewed-by: Hans Wennborg <hans@chromium.org>
Commit-Queue: Nico Weber <thakis@chromium.org>
Cr-Commit-Position: refs/heads/main@{#957081}
---

diff --git a/tools/clang/scripts/update.py b/tools/clang/scripts/update.py
index 23d0f00..8224d4a 100755
--- a/tools/clang/scripts/update.py
+++ b/tools/clang/scripts/update.py
@@ -28,6 +28,7 @@
 import urllib.request
 import urllib.error
 import zipfile
+import zlib
 
 
 # Do NOT CHANGE this if you don't know what you're doing -- see
@@ -96,16 +97,27 @@
     try:
       sys.stdout.write('Downloading %s ' % url)
       sys.stdout.flush()
-      response = urllib.request.urlopen(url)
+      request = urllib.request.Request(url)
+      request.add_header('Accept-Encoding', 'gzip')
+      response = urllib.request.urlopen(request)
       total_size = int(response.info().get('Content-Length').strip())
+
+      is_gzipped = response.info().get('Content-Encoding', '').strip() == 'gzip'
+      if is_gzipped:
+        gzip_decode = zlib.decompressobj(zlib.MAX_WBITS + 16)
+
       bytes_done = 0
       dots_printed = 0
       while True:
         chunk = response.read(CHUNK_SIZE)
         if not chunk:
           break
-        output_file.write(chunk)
         bytes_done += len(chunk)
+
+        if is_gzipped:
+          chunk = gzip_decode.decompress(chunk)
+        output_file.write(chunk)
+
         num_dots = TOTAL_DOTS * bytes_done // total_size
         sys.stdout.write('.' * (num_dots - dots_printed))
         sys.stdout.flush()
@@ -113,6 +125,8 @@
       if bytes_done != total_size:
         raise urllib.error.URLError("only got %d of %d bytes" %
                                     (bytes_done, total_size))
+      if is_gzipped:
+        output_file.write(gzip_decode.flush())
       print(' Done.')
       return
     except urllib.error.URLError as e:
